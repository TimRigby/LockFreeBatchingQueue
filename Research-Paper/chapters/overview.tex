\setcounter{subsection}{0}
The Lock Free Queue with Batching is a direct extension of the basic concurrent Lock Free Queue. Our first step in building this data structure is to begin with a well-performing lock free queue implementation. The Lock Free Queue with Batching allows for quick computation of its size by maintaining counters with the head and tail of the shared queue. Batching threads will receive enqueue and dequeue operations to execute locally, building a subsequence of a queue that can be then applied to the shared queue atomically to perform multiple enqueue and dequeue operations in a single access to the shared queue. Local threads will also track the number of dequeue operations taking place to be able to quickly modify the shared queue as needed while applying the batch. When a batch is applied to the shared queue, a descriptor like object replaces the head of the queue in order to have all other threads assist the completion of the batching event. 

\subsection{Our Implementation}
 There are a few differences between our implementation and the papers original implementation. The first thing was that since the original paper implemented the data structure in C++ it made use of the \textit{Union} operator which allowed different objects to share the same memory location. Java unfortunately does not have similar functionality do to not having low level memory access. To work around this we had to make some new data structures which we mention in section 4.1.

Another key thing was that certain functionality regarding keeping track of excess dequeues, and certain interface functions were described in the paper, but there was no examples in pseudo code to reference. Because of this, we had to write our own implementation of these methods which resulted in a bit different layout that the original version. This was one of the tougher obstacles we faced in our re-implementation since it require a lot of debugging, and trial and error to get the correct working version of the data structure.  